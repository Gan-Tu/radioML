{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D, Input, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300 sequences of 100-bits sequences\n",
    "data_path = \"data/viterbi_dump_k100_n300.pk\"\n",
    "data = pickle.load(open(data_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.05, 3), (0.1, 0.05, 5), (0.1, 0.1, 3), (0.1, 0.1, 5), (0.1, 0.15, 3), (0.1, 0.15, 5), (0.1, 0.2, 3), (0.1, 0.2, 5), (0.1, 0.3, 3), (0.1, 0.3, 5), (0.1, 0.5, 3), (0.1, 0.5, 5), (0.1, 0.8, 3), (0.1, 0.8, 5), (0.5, 0.05, 3), (0.5, 0.05, 5), (0.5, 0.1, 3), (0.5, 0.1, 5), (0.5, 0.15, 3), (0.5, 0.15, 5), (0.5, 0.2, 3), (0.5, 0.2, 5), (0.5, 0.3, 3), (0.5, 0.3, 5), (0.5, 0.5, 3), (0.5, 0.5, 5), (0.5, 0.8, 3), (0.5, 0.8, 5), (0.81, 0.05, 3), (0.81, 0.05, 5), (0.81, 0.1, 3), (0.81, 0.1, 5), (0.81, 0.15, 3), (0.81, 0.15, 5), (0.81, 0.2, 3), (0.81, 0.2, 5), (0.81, 0.3, 3), (0.81, 0.3, 5), (0.81, 0.5, 3), (0.81, 0.5, 5), (0.81, 0.8, 3), (0.81, 0.8, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message_seqs = list()\n",
    "noisy_seqs = list()\n",
    "viterbi_decoded_seqs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in data.items():\n",
    "#     if k[1] > 0.5:\n",
    "#         continue\n",
    "    message_seqs.append(d[0])\n",
    "    noisy_seqs.append(d[1])\n",
    "    viterbi_decoded_seqs.append(d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_seqs = np.concatenate(np.array(message_seqs))\n",
    "noisy_seqs = np.concatenate(np.array(noisy_seqs))\n",
    "viterbi_decoded_seqs = np.concatenate(np.array(viterbi_decoded_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12600, 100)\n",
      "(12600,)\n",
      "(12600,)\n"
     ]
    }
   ],
   "source": [
    "print(message_seqs.shape)\n",
    "print(noisy_seqs.shape)\n",
    "print(viterbi_decoded_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([204, 208])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noisy sequences have two lengths\n",
    "np.unique([len(x) for x in noisy_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102, 104])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viterbi_decoded sequences have two lengths\n",
    "np.unique([len(x) for x in viterbi_decoded_seqs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems that noisy sequences and viterbi decoding outputs various length sequences, but generally the additional bytes at the end are preample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(low=0, high=len(message_seqs))\n",
    "message_seqs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_decoded_seqs[idx].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_loss(ground_truth, decodes):\n",
    "    if len(ground_truth) != len(decodes):\n",
    "        raise ValueError(\"ground_truth and decodes have different length: {0} and {1}\"\n",
    "                            .format(len(ground_truth), len(decodes)))\n",
    "    l = 0.0\n",
    "    for g, d in zip(ground_truth, decodes):\n",
    "        l += sum(abs(g - d[:len(g)]))\n",
    "    return l / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.90396825396825"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss(message_seqs, viterbi_decoded_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Length Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([204, 208])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noisy sequences have two lengths\n",
    "np.unique([len(x) for x in noisy_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102, 104])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viterbi_decoded sequences have two lengths\n",
    "np.unique([len(x) for x in viterbi_decoded_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarlize length of noisy_inputs\n",
    "noisy_seqs_sameLength = np.array([x if len(x) == 208 else np.concatenate([x, [0,0,0,0]]) \n",
    "                                      for x in noisy_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12600, 100)\n",
      "(12600, 208)\n"
     ]
    }
   ],
   "source": [
    "# Now input lengths are standardized\n",
    "print(message_seqs.shape)\n",
    "print(noisy_seqs_sameLength.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = noisy_seqs_sameLength.astype(\"float64\")\n",
    "Y = message_seqs.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8349, 8014, 1985, ..., 5894, 3427, 6924])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies = np.arange(len(X))\n",
    "np.random.shuffle(indicies)\n",
    "indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.2\n",
    "split_idx = int(len(X) * (1 - train_test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[indicies[:split_idx]], X[indicies[split_idx:]]\n",
    "Y_train, Y_test = Y[indicies[:split_idx]], Y[indicies[split_idx:]]\n",
    "viterbi_decoded_train = [x[:100] for x in viterbi_decoded_seqs[indicies[:split_idx]]]\n",
    "viterbi_decoded_test = [x[:100] for x in viterbi_decoded_seqs[indicies[split_idx:]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64,  activation=None, input_shape=(208,), \n",
    "                kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(128, activation=None, \n",
    "                kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(256, activation=None, \n",
    "                kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(128, activation=None, \n",
    "                kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(100, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=25, verbose=1, \n",
    "          validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(preds):\n",
    "    result = []\n",
    "    for pred in preds:\n",
    "        result.append([1 if x >= 0.5 else 0 for x in pred])\n",
    "    return np.array(result).astype(\"float64\")\n",
    "def test(input_x, target_label, viterbi_output, test_model):\n",
    "    viterbi_avg_loss = avg_loss(target_label, viterbi_output)\n",
    "    model_avg_loss = avg_loss(target_label, threshold(test_model.predict(input_x)))\n",
    "    print(\"average loss for viterbi decoding is: {0:.4f}; acc {1:.4f}\".format(\n",
    "                viterbi_avg_loss, 1 - viterbi_avg_loss/input_x.shape[1]))\n",
    "    print(\"average loss for model is: {0:.4f}; acc {1:.4f}\".format(\n",
    "                model_avg_loss, 1 - model_avg_loss/input_x.shape[1]))\n",
    "    print(\"## Random Example ##\")\n",
    "    test_idx = np.random.randint(0, high=len(input_x))\n",
    "    test_truth = target_label[test_idx]\n",
    "    #test_pred = test_model.predict(input_x[test_idx:test_idx+1])[0]\n",
    "    test_pred_thresholded = threshold(test_model.predict(input_x[test_idx:test_idx+1]))[0]\n",
    "    diff = abs(test_pred_thresholded - test_truth)\n",
    "    print(\"ground_truth\\n\", test_truth)\n",
    "    #print(\"prediction\\n\", test_pred)\n",
    "    print(\"prediction_thresholded\\n\", test_pred_thresholded)\n",
    "    print(\"DIFFERENCE (acc {0:.4f}%)\\n\".format(1-sum(diff)/len(test_pred_thresholded)), diff)\n",
    "    print(\"dummy baseline (set every bit to the most occuring bit) can get {0}% accurate\".format(\n",
    "                max(sum(test_truth), 100-sum(test_truth))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(X_test, Y_test, viterbi_decoded_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test various feedforward networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FF_MODELS = [\n",
    "    [32, 100],\n",
    "    [64, 100],\n",
    "    [128, 100],\n",
    "    [256, 100],\n",
    "    [32, 32, 100],\n",
    "    [32, 64, 100],\n",
    "    [64, 64, 100],\n",
    "    [64, 128, 100],\n",
    "    [128, 128, 100],\n",
    "    [128, 256, 100],\n",
    "    [256, 256, 100],\n",
    "    [32,128,128,100],\n",
    "    [32,128,256,100],\n",
    "    [32,256,256,100],\n",
    "    [32,128,256,128,100],\n",
    "    [32,128,128,128,100],\n",
    "    [1024,512,100],\n",
    "    [512,256,100],\n",
    "    [256,128,100],\n",
    "    [128,100,100]\n",
    "]\n",
    "\n",
    "ACTIVATIONS = [None, \"relu\"]\n",
    "L2 = 1e-7\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "VALIDATION_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ffn_build_and_evaluate_performance(layers, activation=\"None\", verbose=2, \n",
    "                                   input_shape=(208,), validation_split=VALIDATION_RATIO):\n",
    "    if layers[-1] != 100:\n",
    "        raise ValueError(\"last output dimension has to be 100\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i, hidden_units in enumerate(layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(hidden_units, activation=activation, \n",
    "                            input_shape=input_shape, kernel_regularizer=regularizers.l2(L2)))\n",
    "        elif i == len(layers) - 1:\n",
    "            model.add(Dense(hidden_units, activation=\"sigmoid\",\n",
    "                           kernel_regularizer=regularizers.l2(L2)))\n",
    "        else:\n",
    "            model.add(Dense(100, activation=activation, kernel_regularizer=regularizers.l2(L2)))\n",
    "            \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=verbose, \n",
    "              validation_split=validation_split, shuffle=True)\n",
    "    \n",
    "    return model, avg_loss(Y_test, threshold(model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(lst, act):\n",
    "    return \"[{0}]-{1}\".format(\",\".join([str(x) for x in lst]), act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32,100]-None loss: 39.1067\n",
      "[32,100]-relu loss: 39.3381\n",
      "[64,100]-None loss: 40.0048\n",
      "[64,100]-relu loss: 39.3159\n",
      "[128,100]-None loss: 39.7810\n",
      "[128,100]-relu loss: 38.8710\n",
      "[256,100]-None loss: 39.4921\n",
      "[256,100]-relu loss: 39.0508\n",
      "[32,32,100]-None loss: 39.0020\n",
      "[32,32,100]-relu loss: 39.1937\n",
      "[32,64,100]-None loss: 39.2079\n",
      "[32,64,100]-relu loss: 39.2833\n",
      "[64,64,100]-None loss: 40.3151\n",
      "[64,64,100]-relu loss: 36.6774\n",
      "[64,128,100]-None loss: 39.8548\n",
      "[64,128,100]-relu loss: 36.5746\n",
      "[128,128,100]-None loss: 39.2095\n",
      "[128,128,100]-relu loss: 36.5591\n",
      "[128,256,100]-None loss: 39.9813\n",
      "[128,256,100]-relu loss: 36.6901\n",
      "[256,256,100]-None loss: 39.6996\n",
      "[256,256,100]-relu loss: 37.2758\n",
      "[32,128,128,100]-None loss: 38.5710\n",
      "[32,128,128,100]-relu loss: 37.6992\n",
      "[32,128,256,100]-None loss: 38.8147\n",
      "[32,128,256,100]-relu loss: 36.9992\n",
      "[32,256,256,100]-None loss: 38.5742\n",
      "[32,256,256,100]-relu loss: 37.4948\n",
      "[32,128,256,128,100]-None loss: 39.4413\n",
      "[32,128,256,128,100]-relu loss: 36.9464\n",
      "[32,128,128,128,100]-None loss: 38.7067\n",
      "[32,128,128,128,100]-relu loss: 36.7889\n",
      "[1024,512,100]-None loss: 39.4456\n",
      "[1024,512,100]-relu loss: 36.9075\n",
      "[512,256,100]-None loss: 38.6782\n",
      "[512,256,100]-relu loss: 37.6750\n",
      "[256,128,100]-None loss: 39.1917\n",
      "[256,128,100]-relu loss: 36.8278\n",
      "[128,100,100]-None loss: 39.7758\n",
      "[128,100,100]-relu loss: 37.3627\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "for m in FF_MODELS:\n",
    "    for a in ACTIVATIONS:\n",
    "        k = name(m, a)\n",
    "        model, loss = ffn_build_and_evaluate_performance(m, activation=a, verbose=0)\n",
    "        results[k] = (model, loss)\n",
    "        print(\"{0} loss: {1:.4f}\".format(k, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss for viterbi decoding is: 33.9929; acc 0.8366\n",
      "average loss for model is: 36.5591; acc 0.8242\n",
      "## Random Example ##\n",
      "ground_truth\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1.]\n",
      "prediction_thresholded\n",
      " [1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0.]\n",
      "DIFFERENCE (acc 0.4600%)\n",
      " [0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 1.]\n",
      "dummy baseline (set every bit to the most occuring bit) can get 82.0% accurate\n"
     ]
    }
   ],
   "source": [
    "test(X_test, Y_test, viterbi_decoded_test, results[\"[128,128,100]-relu\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = results[\"[128,128,100]-relu\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.save(\"models/ecc-ffn-128-128-100-relu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8064 samples, validate on 2016 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 0.2491 - acc: 0.0097 - val_loss: 0.2454 - val_acc: 0.0045\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.2363 - acc: 0.0403 - val_loss: 0.2295 - val_acc: 0.0119\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2213 - acc: 0.0435 - val_loss: 0.2236 - val_acc: 0.0565\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2133 - acc: 0.0668 - val_loss: 0.2196 - val_acc: 0.0570\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2062 - acc: 0.0809 - val_loss: 0.2149 - val_acc: 0.0799\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1986 - acc: 0.1173 - val_loss: 0.2139 - val_acc: 0.0283\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1930 - acc: 0.0784 - val_loss: 0.2119 - val_acc: 0.0769\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1880 - acc: 0.1017 - val_loss: 0.2117 - val_acc: 0.0655\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1845 - acc: 0.0996 - val_loss: 0.2119 - val_acc: 0.0694\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1813 - acc: 0.0914 - val_loss: 0.2128 - val_acc: 0.0759\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1787 - acc: 0.0720 - val_loss: 0.2160 - val_acc: 0.1195\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.1765 - acc: 0.0952 - val_loss: 0.2155 - val_acc: 0.1280\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.1744 - acc: 0.1028 - val_loss: 0.2163 - val_acc: 0.0774\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.1727 - acc: 0.1114 - val_loss: 0.2172 - val_acc: 0.0794\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.1713 - acc: 0.1238 - val_loss: 0.2181 - val_acc: 0.0531\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.1699 - acc: 0.1055 - val_loss: 0.2185 - val_acc: 0.1136\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.1688 - acc: 0.1221 - val_loss: 0.2214 - val_acc: 0.1022\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.1678 - acc: 0.1381 - val_loss: 0.2206 - val_acc: 0.0992\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.1670 - acc: 0.1174 - val_loss: 0.2205 - val_acc: 0.1364\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.1664 - acc: 0.1334 - val_loss: 0.2207 - val_acc: 0.1300\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.1657 - acc: 0.1404 - val_loss: 0.2214 - val_acc: 0.1171\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.1652 - acc: 0.1318 - val_loss: 0.2222 - val_acc: 0.1106\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.1648 - acc: 0.1384 - val_loss: 0.2225 - val_acc: 0.1225\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.1644 - acc: 0.1385 - val_loss: 0.2232 - val_acc: 0.1195\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.1640 - acc: 0.1334 - val_loss: 0.2234 - val_acc: 0.1181\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.1637 - acc: 0.1518 - val_loss: 0.2241 - val_acc: 0.0878\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.1634 - acc: 0.1357 - val_loss: 0.2244 - val_acc: 0.1344\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1632 - acc: 0.1339 - val_loss: 0.2249 - val_acc: 0.1443\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.1629 - acc: 0.1363 - val_loss: 0.2249 - val_acc: 0.1220\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1627 - acc: 0.1324 - val_loss: 0.2251 - val_acc: 0.1230\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1626 - acc: 0.1384 - val_loss: 0.2254 - val_acc: 0.1344\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1625 - acc: 0.1264 - val_loss: 0.2258 - val_acc: 0.1364\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1624 - acc: 0.1472 - val_loss: 0.2265 - val_acc: 0.1161\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1621 - acc: 0.1319 - val_loss: 0.2259 - val_acc: 0.0893\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1619 - acc: 0.1308 - val_loss: 0.2261 - val_acc: 0.0843\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1617 - acc: 0.1283 - val_loss: 0.2265 - val_acc: 0.1270\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1615 - acc: 0.1370 - val_loss: 0.2266 - val_acc: 0.1225\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1615 - acc: 0.1302 - val_loss: 0.2265 - val_acc: 0.1007\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1613 - acc: 0.1297 - val_loss: 0.2268 - val_acc: 0.1215\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1612 - acc: 0.1348 - val_loss: 0.2271 - val_acc: 0.1121\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1610 - acc: 0.1355 - val_loss: 0.2280 - val_acc: 0.1176\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1608 - acc: 0.1312 - val_loss: 0.2277 - val_acc: 0.1186\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1612 - acc: 0.1311 - val_loss: 0.2279 - val_acc: 0.1071\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1609 - acc: 0.1291 - val_loss: 0.2285 - val_acc: 0.1052\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1606 - acc: 0.1369 - val_loss: 0.2286 - val_acc: 0.0893\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1602 - acc: 0.1267 - val_loss: 0.2287 - val_acc: 0.1081\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1600 - acc: 0.1333 - val_loss: 0.2290 - val_acc: 0.0972\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1598 - acc: 0.1272 - val_loss: 0.2288 - val_acc: 0.1161\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1597 - acc: 0.1345 - val_loss: 0.2302 - val_acc: 0.1171\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1595 - acc: 0.1280 - val_loss: 0.2301 - val_acc: 0.1086\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1594 - acc: 0.1295 - val_loss: 0.2302 - val_acc: 0.0933\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1592 - acc: 0.1342 - val_loss: 0.2301 - val_acc: 0.0977\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1590 - acc: 0.1295 - val_loss: 0.2300 - val_acc: 0.1012\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1588 - acc: 0.1338 - val_loss: 0.2307 - val_acc: 0.1161\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1587 - acc: 0.1297 - val_loss: 0.2314 - val_acc: 0.0838\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.1585 - acc: 0.1312 - val_loss: 0.2317 - val_acc: 0.1002\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1583 - acc: 0.1285 - val_loss: 0.2325 - val_acc: 0.0982\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1582 - acc: 0.1292 - val_loss: 0.2315 - val_acc: 0.1062\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1582 - acc: 0.1281 - val_loss: 0.2323 - val_acc: 0.0893\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1583 - acc: 0.1332 - val_loss: 0.2320 - val_acc: 0.0937\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1579 - acc: 0.1281 - val_loss: 0.2330 - val_acc: 0.0938\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1576 - acc: 0.1301 - val_loss: 0.2330 - val_acc: 0.1057\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1575 - acc: 0.1257 - val_loss: 0.2331 - val_acc: 0.0957\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1574 - acc: 0.1319 - val_loss: 0.2342 - val_acc: 0.1012\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1574 - acc: 0.1298 - val_loss: 0.2334 - val_acc: 0.0903\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1572 - acc: 0.1310 - val_loss: 0.2338 - val_acc: 0.0818\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1571 - acc: 0.1251 - val_loss: 0.2347 - val_acc: 0.0997\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.1569 - acc: 0.1262 - val_loss: 0.2342 - val_acc: 0.1062\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1568 - acc: 0.1333 - val_loss: 0.2347 - val_acc: 0.1027\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.1567 - acc: 0.1282 - val_loss: 0.2347 - val_acc: 0.0933\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1566 - acc: 0.1281 - val_loss: 0.2355 - val_acc: 0.0942\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.1566 - acc: 0.1323 - val_loss: 0.2356 - val_acc: 0.0868\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.1565 - acc: 0.1231 - val_loss: 0.2354 - val_acc: 0.0957\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.1563 - acc: 0.1244 - val_loss: 0.2353 - val_acc: 0.0923\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.1561 - acc: 0.1286 - val_loss: 0.2363 - val_acc: 0.1052\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.1560 - acc: 0.1239 - val_loss: 0.2361 - val_acc: 0.1027\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.1561 - acc: 0.1291 - val_loss: 0.2363 - val_acc: 0.0923\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.1559 - acc: 0.1235 - val_loss: 0.2364 - val_acc: 0.1002\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.1555 - acc: 0.1285 - val_loss: 0.2368 - val_acc: 0.1022\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.1554 - acc: 0.1283 - val_loss: 0.2369 - val_acc: 0.0957\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.1552 - acc: 0.1296 - val_loss: 0.2373 - val_acc: 0.0838\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.1551 - acc: 0.1264 - val_loss: 0.2371 - val_acc: 0.1022\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.1551 - acc: 0.1270 - val_loss: 0.2373 - val_acc: 0.1066\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.1550 - acc: 0.1266 - val_loss: 0.2377 - val_acc: 0.0997\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.1549 - acc: 0.1310 - val_loss: 0.2377 - val_acc: 0.1012\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.1548 - acc: 0.1307 - val_loss: 0.2387 - val_acc: 0.0982\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.1547 - acc: 0.1288 - val_loss: 0.2387 - val_acc: 0.0853\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.1546 - acc: 0.1261 - val_loss: 0.2388 - val_acc: 0.0923\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.1544 - acc: 0.1261 - val_loss: 0.2389 - val_acc: 0.0997\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.1543 - acc: 0.1300 - val_loss: 0.2389 - val_acc: 0.0878\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.1542 - acc: 0.1257 - val_loss: 0.2389 - val_acc: 0.0952\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.1541 - acc: 0.1307 - val_loss: 0.2394 - val_acc: 0.0962\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1541 - acc: 0.1257 - val_loss: 0.2400 - val_acc: 0.1022\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1540 - acc: 0.1286 - val_loss: 0.2401 - val_acc: 0.1032\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1540 - acc: 0.1326 - val_loss: 0.2399 - val_acc: 0.0878\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1538 - acc: 0.1288 - val_loss: 0.2401 - val_acc: 0.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 0s - loss: 0.1537 - acc: 0.1317 - val_loss: 0.2402 - val_acc: 0.0942\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1536 - acc: 0.1312 - val_loss: 0.2416 - val_acc: 0.1032\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1536 - acc: 0.1291 - val_loss: 0.2410 - val_acc: 0.0972\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1535 - acc: 0.1298 - val_loss: 0.2407 - val_acc: 0.0977\n"
     ]
    }
   ],
   "source": [
    "L2 = 1e-7\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "VALIDATION_RATIO = 0.2\n",
    "model, loss = ffn_build_and_evaluate_performance([100,100,100], activation=\"relu\", verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(X_test, Y_test, viterbi_decoded_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation: The model overfits always by guessing everything to be the value of the most dominating digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILTERS = \n",
    "# KERNAL_SIZE = \n",
    "# DROPOUT_PROB = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=(208,)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(48, kernel_size, strides=(1, 1), \n",
    "                 padding='same', activation=\"relu\"))\n",
    "model.add(Conv2D(128, kernel_size, strides=(1, 1), \n",
    "                 padding='same', activation=\"relu\"))\n",
    "# AveragePooling2D(pool_size=(2, 2), strides=None, padding='same')\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(192, kernel_size, strides=(1, 1), \n",
    "                 padding='same', activation=\"relu\"))\n",
    "model.add(Conv2D(filters, kernel_size, strides=(1, 1), \n",
    "                 padding='same', activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(100, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cnn_build_and_evaluate_performance(layers, activation=\"relu\", verbose=2, \n",
    "#                                    input_shape=(208,), validation_split=VALIDATION_RATIO):\n",
    "#     if layers[-1] != 100:\n",
    "#         raise ValueError(\"last output dimension has to be 100\")\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     for i, hidden_units in enumerate(layers):\n",
    "#         if i == 0:\n",
    "#             model.add(Conv2D(filters=FILTERS, kernel_size=KERNAL_SIZE, strides=(1, 1), \n",
    "#                  padding='valid', activation=None))\n",
    "#         elif i == len(layers) - 1:\n",
    "#             model.add(Conv2D(filters=FILTERS, kernel_size=KERNAL_SIZE, strides=(1, 1), \n",
    "#                  padding='valid', activation=None))\n",
    "#         else:\n",
    "#             model.add(Conv2D(filters=FILTERS, kernel_size=KERNAL_SIZE, strides=(1, 1), \n",
    "#                  padding='valid', activation=None))\n",
    "            \n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='binary_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=verbose, \n",
    "#               validation_split=validation_split, shuffle=True)\n",
    "    \n",
    "#     return model, avg_loss(Y_test, threshold(model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
